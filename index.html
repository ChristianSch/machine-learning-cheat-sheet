<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <link rel="stylesheet" href="css/main.css" type="text/css" media="all">

        <!-- typeplate -->
        <link rel="stylesheet" href="css/typeplate.css" type="text/css" media="all">

        <!-- MathJax -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                extensions: ["tex2jax.js"],
                jax: ["input/TeX", "output/HTML-CSS"],
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true
                },
                "HTML-CSS": { availableFonts: ["TeX"] }
            });
        </script>
        <script type="text/javascript" src="js/MathJax/MathJax.js"></script>

        <!-- Highlight.js -->
        <link rel="stylesheet" href="js/Highlight.js/styles/default.css">
        <script src="js/Highlight.js/highlight.pack.js" type="text/javascript"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </head>

    <body id="top">
        <div id="main-wrap">
            <h1>Machine Learning @ Coursera</h1>
            <h2 class="sub-h2">A cheat sheet</h2>

            <p>This cheatsheet wants to provide an overview of the concepts and the used formulas and definitions of the <em>»Machine Learning«</em> <a href="https://class.coursera.org/ml-008" title="Coursera Online Course: Machine Learning">online course at coursera</a>.</p>

            <div id="last-change">
                <p>Last changed: <time datetime="2015-02-17">February 17th, 2015</time></p>
            </div>

            <p><strong>Please note:</strong> I changed the notation very slighty. I'll denote vectors with a little arrow on the top. Example: $\vec\theta$</p>

            <p>The <a href="octave.html" title="octave tutorial">octave tutorial</a> that was part of the seond week is available as a script <a href="octave.html" title="octave tutorial">here</a>.</p>

            <h2 class="week-indicator" id="week-1">Week 1<a class="anchor-link" href="#week-1"></a></h2>

            <h3 id="intro">Introduction<a class="anchor-link" href="#intro"></a></h3>

            <h4 class="definition" id="def-ml">Machine Learning<a class="anchor-link" href="#def-ml"></a></h4>
            <blockquote>
                »Well-posed Learning Problem: A computer program is said to <em>learn</em>
                from experience E with respect to some task T and some performance measure E,
                if its performance on T, as measured by P, improves with experience E.«
                <br>
                — <cite>Tom Mitchell (1998)</cite>
                <sup><a href="#footnote1">[1]</a></sup>
            </blockquote>

            <h4 class="definition" id="def-sl">Supervised Learning<a class="anchor-link" href="#def-sl"></a></h4>
            TODO

            <h4 class="definition" id="def-ul">Unsupervised Learning<a class="anchor-link" href="#def-ul"></a></h4>
            TODO

            <h4 class="definition" id="def-reg-prob">Regression Problem<a class="anchor-link" href="#def-reg-prob"></a></h4>
            TODO

            <h4 class="definition" id="def-class-prob">Classification Problem<a class="anchor-link" href="#def-class-prob"></a></h4>
            TODO

            <h3 id="univariate-lin-reg">Linear Regression with One Variable<a class="anchor-link" href="#univariate-lin-reg"></a></h3>
            <h4 id="model-rep">Model Representation<a class="anchor-link" href="#model-rep"></a></h4>
            <p>
                <strong>Notations:</strong>
                <ul>
                    <li>$m$: number of training examples</li>
                    <li>$x$'s: <em>input</em> variable/features</li>
                    <li>$y$'s: <em>output</em> variables/<em>target</em variable></li>
                    <li>$(x,y)$: one training example</li>
                    <li>$(x^{(i)},y^{(i)})$: $i$<sup>th</sup> training example</li>
                </ul>
            </p>

            <h5 class="definition" id="univariate-hypothesis">Univariate Hypothesis<a class="anchor-link" href="#univariate-hypothesis"></a></h5>
            <p>The hypothesis function maps <em>x's</em> to <em>y's</em> ($h: x \mapsto y$). It can be represented by:</p>

            $$h_{\theta} = \theta_{0} + \theta_{1}x$$

            <p>The shorthand for the hypothesis is $h(x)$. $\theta_{i}$'s are called the parameters of the hypothesis.
            In this case the hypothesis is called <em>»Univariate Linear Regression«</em>.</p>

            <h4 id="cost-function">Cost Function<a class="anchor-link" href="#cost-function"></a></h4>
            <h5 class="definition" id="def-secf">Squared Error Cost Function<a class="anchor-link" href="#def-secf"></a></h5>
            $$J(\theta_0, \theta_1) = \frac{1}{2m} \sum^{m}_{i=1}\left(h_{\theta}(x^{(i)}) - y^{(i)}\right)^2$$

            <h4 class="def" id="grad-dec">The Gradient Descent Algorithm<a class="anchor-link" href="#grad-dec"></a></h4>
            <p>The goal is to choose the hypothises' parameters in a manner that the the output of the cost function $J(\theta_0, \theta_1)$ is minimal.</p>

            <p><strong>Outline:</strong>
                <ul>
                    <li>Start with some $\theta_0, \theta_1$</li>
                    <li>Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0, \theta_1)$ until we hopefully end up at a minimum</li>
                </ul>
            </p>

            <h5 class="definition" id="def-grad-dec">Gradient Descent Algorithm<a class="anchor-link" href="#def-grad-dec"></a></h5>
            <p>Note that the values of $\theta_0$ and $\theta_1$ are updated simultaneously. $\alpha$ is called the <em>learning rate.</em></p>
            $$\begin{aligned}
            \text{repeat} & \text{ until convergence} \; \{\\
            & \theta_j := \theta_j - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1) \;\; \text{(for j=0 and j=1)}\\
            \} \phantom{15pt} &
            \end{aligned}$$

            <p>The correct implementation of the simultaneous update looks like this:</p>
            $$\begin{aligned}
            & temp0 := \theta_0 - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1)\\
            & temp1 := \theta_1 - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1)\\
            & \theta_0 := temp0 \\
            & \theta_1 := temp1
            \end{aligned}$$ 

            <h5 id="part-der-cf">Partial derivitive of the cost function<a class="anchor-link" href="#part-der-cf"></a></h5>
            $$\begin{aligned}
            \text{repeat} & \text{ until convergence} \; \{\\
            & \theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^{m}_{i=0}\left(h_\theta(x^{(i)}) - y^{(i)}\right)\\
            & \theta_1 := \theta_1 - \alpha \frac{1}{m} \sum^{m}_{i=0}\left(h_\theta(x^{(i)}) - y^{(i)}\right) \cdot x^{(i)}\\
            \} \phantom{15pt} &
            \end{aligned}$$


            <p><strong>Note:</strong> The cost function $J(\theta_0, \theta_1)$ is <em>convex</em> and therefore has only one optimum overall.</p>

            <h5 class="definition" id="def-batch-grad-dec">Batch Gradient Descent<a class="anchor-link" href="#def-batch-grad-dec"></a></h5>
            <p>If the gradient descent uses all $m$ training examples in each iteration it is also called <em>Batch Gradient Descent Algorithm</em>.</p>

            <h2 class="week-indicator" id="week-2">Week 2<a class="anchor-link" href="#week-2"></a></h2>
            <h3 id="multivariate-lin-reg">Linear Regression with Multiple Variables<a class="anchor-link" href="#multivariate-lin-reg"></a></h3>
            <h4 id="multiple-features">Multiple Features<a class="anchor-link" href="#multiple-features"></a></h4>
            <p>
                <strong>Notations:</strong>
                <ul>
                    <li>$n$: number of features</li>
                    <li>$\vec x^{(i)}$: input features of <em>i<sup>th<sup></em> training example</li>
                    <li>$x^{(i)}_j$: value of feature $j$ in <em>i<sup>th<sup></em> training example</li>
                </ul>
            </p>

            <h5 class="definition" id="multivariate-hypothesis">Multivariate Hypothesis<a class="anchor-link" href="#multivariate-hypothesis"></a></h5>
            $$h_\theta = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n$$

            <p>For convenience of notation we'll define $x_0 = 1$ ($x_0^{(i)}$). Thus a feature vector looks like:</p>

            $$ \vec x = \left[\begin{array}{c} x_0\\ x_1 \\ \vdots \\ x_n \end{array}\right] \in \mathbb{R}^{n+1}$$

            <p>And the parameters can be written as:</p>

            $$ \vec \theta = \left[\begin{array}{c} \theta_0\\ \theta_1 \\ \vdots \\ \theta_n \end{array}\right] \in \mathbb{R}^{n+1}$$

            <p>The hypothesis can now be written as:</p>

            $$\begin{align}
            h_\theta & = \theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n\\
            & = \left[ \theta_0 \theta_1 \cdots \theta_n \right] \left[\begin{array}{c} \theta_0\\ \theta_1 \\ \vdots \\ \theta_n \end{array}\right] \\
            & = \boxed{\vec\theta^{T}\vec x}\\
            \end{align}$$

            <p>This hypothesis is called <em>»Multivariate Linear Regression«</em>.</p>

            <h4 id="multivar-grad-desc">Gradient Descent for Multiple Variables<a class="anchor-link" href="#multivar-grad-desc"></a></h4>
            <p>The cost function can now be written as:</p>

            $$\begin{aligned}
            J(\theta_0, \theta_1, ..., \theta_n) & = \frac{1}{2m}\sum^{m}_{i=1} \left(h_\theta(x^{(i)}) - y^{(i)}\right)^2\\
            & = \boxed{J(\vec\theta)}
            \end{aligned}$$

            <p>The gradient descent algorithm for this cost function looks like this:</p>

            $$\begin{aligned}
            \text{repeat} & \{\\
            & \theta_j := \theta_j - \alpha \frac{\delta}{\delta \theta_j} \; \; J(\theta_0, \theta_1, ... , \theta_n)\\
            \} \phantom{15pt} &
            \end{aligned}$$

            <p>Which can also be written like this:</p>
            $$\begin{aligned}
            \text{repeat} & \{\\
            & \theta_j := \theta_j - \alpha \frac{1}{m} \sum^{m}_{i=1}\left( h_\theta(\vec x^{(i)}) -y^{(i)} \right) x_j^{(i)}) \\
            \} \phantom{15pt} &
            \end{aligned}$$

            <p>Again, the parameters $\theta_j \; \forall j= 0, ..., n$ have to be updated simultaneously.</p>

            <h5 id="feature-scaling">Feature Scaling<a class="anchor-link" href="#feature-scaling"></a></h5>
            <p>Get every feature into approximately a $-1 \leq x_i \leq 1$ range to
            optimize the path finding of the gradient descent algorithm.</p>

            <h6 id="mean-norm">Mean Normalization<a class="anchor-link" href="#mean-norm"></a></h6>
            <p>Replace $x_i$ with $x_i - \mu_i$ to make features have approximately zero mean
            (does not apply to $x_0 = 1$).</p>

            $$x_1 \leftarrow \frac{x_1 - \mu_1}{s_1}$$

            <p>where $\mu_1$ is the average value of x in the training set and $s_1$ is
            the range $max - min$ (or standard deviation).</p>

            <h5 id="learning-rate">Learning Rate $\alpha$<a class="anchor-link" href="#learning-rate"></a></h5>
            <p>General rule: $J(\vec\theta)$ should decrease after every iteration.</p>

            <h6>Example Automatic Convergence Test</h6>
            <p>Declare convergence if $J(\vec\theta)$ decreases by less than $\epsilon = 10^{-3}$ in one iteration.</p>

            <p>Make sure gradient descent works correctly:</p>

            <ul>
                <li>If $\alpha$ is too small: slow convergence</li>
                <li>If $\alpha$ is too large: $J(\vec\theta)$ may not decrease on every iteration and may not converge</li>
            </ul>

            <p>For $\alpha$ try: $0.001$, $0.003$, $0.01$, $0.03$, $0.1$, $0.3$, $1$ etc.</p>

            
            <h4 id="poly-reg">Features and Polynomial Regression<a class="anchor-link" href="#poly-reg"></a></h4>
            <p>You can choose your model to fit to a polynomial if you want it to behave in a
            specific way. You not only can choose to multiply/divide two or more features to create
            a new feature, you can also fit your model to a more complex polynomial. If you want your 
            model to behave for example to increase you could choose to use $(size)^2$, fit it to a 
            cubic polynomial the same way, or use $\sqrt{size}$.</p>


            <h4 id="norm-eq">Normal Equation<a class="anchor-link" href="#norm-eq"></a></h4>
            <p>An alternative to the gradient descent algorithm is an analytical solution to
            minimize the cost function $J(\vec\theta)$.</p>

            $$\theta \in \mathbb{R}^{n+1} \;\;\; J(\theta_0, \theta_1, \cdots, \theta_m) = \frac{1}{2m}\sum^{m}_{i=1} \left( h_\theta(x^{(i)} - y^{(i)}\right)^2$$

            $$\frac{\delta}{\delta\theta_j} J(\vec\theta) = \cdots = 0 \;\;\; \text{(for every $j$)}$$

            <p>Then solve for $\theta_0,\theta_1,\cdots,\theta_n$ by setting the equation to equal zero. For $m$ examples $(\vec x^{(i)}, y^{(i)}), \cdots, (\vec x^{(m)}, y^{(m)})$ with $n$ features the input feature of the <em>i<sup>th</sup></em> training example looks like this:</p>

            $$\vec x^{(i)} = \left[ \begin{array}{c} x_0^{(i)}\\ x_1^{(i)} \\ \vdots \\ x_n^{(i)} \end{array} \right] \in \mathbb{R}^{n+1}$$

            <p>The design matrix $x$ then looks like that:</p>

            $$ X = \left[ \begin{array}{c} (x^{(1)})^T \\ (x^{(2)})^T \\ \vdots \\ (x^{(m)})^T \end{array} \right]$$

            <p>and the vector of the outputs of the training examples look like this:</p>

            $$ \vec y = \left[ \begin{array}{c} y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(m)}\end{array}\right]$$

            <p>With the design matrix the minimum $\vec \theta$ is:</p>

            $$ \vec \theta =  (X^TX)^{-1} X^T \vec y$$

            <p>Note: using this method you don't need to scale the features.</p>

            <h4 id="grad-desc-vers-norm-eq">Gradient Descent versus Normal Equation<a class="anchor-link" href="#grad-desc-vers-norm-eq"></a></h4>
            <p>For $m$ training examples and $n$ features:</p>

            <div class="two-col">
                <h5>Gradient Descent:</h5>
                <ul>
                    <li>Need to choose $\alpha$</li>
                    <li>Needs many iterations</li>
                    <li>Works well even when $n$ is large</li>
                </ul>

                <br>
                <br>

                <h5>Normal Equation</h5>
                <ul>
                    <li>No need to choose $\alpha$</li>
                    <li>Don't need to iterate</li>
                    <li>Need to compute $(X^TX)^{-1})$ (complexity $O(n^3)$)</li>
                    <li>Slow if $n$ is very large</li>
                </ul>
            </div>

            <h4 id="norm-eq-noninv">Normal Equation Noninvertibility<a class="anchor-link" href="#norm-eq-noninv"></a></h4>
            <p>Although very rarely, it can happen that $X^TX$ is non-invertible,
            for example if the matrix is singular or degenerate.</p>

            <p>Problems can be that redundant features are used (and therefore the vetors are linearly dependent) or that too many features are used (e.g. $m \leq n$). The solution for that
            would be to delete some features or use regularization (which comes later in this course).</p>

            <h2 class="week-indicator" id="week-3">Week 3<a class="anchor-link" href="#week-3"></a></h2>
            <h3 id="lin-reg-3">Linear Regression<a class="anchor-link" href="#lin-reg-3"></a></h3>
            <p>With $y \in \{0, 1\}$ the linear regression model is</p>

            $$0 \leq h_\theta(x) \leq 1$$

            <h4 id="log-reg-hypo">Hypothesis for Logistic Regression Models<a class="anchor-link" href="#log-reg-hypo"></a></h4>

            <p>The hypothesis for this model is this:</p>

            $$h_\theta(x) = g(\theta^Tx)$$

            <p>Where $g$ is called <em>sigmoid function</em> or <em>logistic function</em></p>

            $$g(z) = \frac{1}{1+e^{-z}}$$

            <p>Which gives us the following representation for the hypothesis:</p>

            $$h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$$            

            <h4 id="hypo-interpr">Interpretation of the Hypothesis Output<a class="anchor-link" href="#hypo-interpr"></a></h4>
            <p>$h_\theta(x)$ is the estimated probability that $y=1$ on input $x$:</p>

            $$h_\theta(x) = P(y = 1 | x ; \theta)$$

            <p>Which reads like <em>probability that $y=1$ given x, parameterized by $\theta$</em></p>

            $$P(y=0|x;\theta) + P(y=1|x;\theta) = 1\\
            P(y=0|x;\theta) = 1 - P(y=1|x;\theta)$$

            <h4 id="decision-boundary">Decision Boundary<a class="anchor-link" href="#decision-boundary"></a></h4>
            <p>Suppose we predict $y=1$ if $h_\theta(x) \geq 0.5$. $g(z) \geq 0.5 $ when $z \geq 0$.
            For $h_\theta(x) = g(\theta^Tx) \geq 0.5$ whenever $z = \theta^Tx \geq 0$. Suppose we
            predict $y=0$ if $h_\theta(x) &lt; 0.5$.</p>
            <p>The decision boundary ist part of the hypothesis. If we for example have a hypothesis with two features, the term $\theta_0 + \theta_1 x_1 + \theta_2 x_2$ gives the decision boundary, where this is the hypothesis:</p>

            $$h_\theta(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2)$$

            <h5 id="non-lin-dec-bound">Non-linear Decision Boundaries<a class="anchor-link" href="#non-lin-dec-bound"></a></h5>
            <p>As <a href="#poly-reg" title="polynomial regression">previously mentioned</a> one can add custom features to fit the hypothesis to the data. This allows us to add custom features that result in a circular decision boundary.</p>
            <p>For example:</p>

            $$\vec \theta = \left[\begin{array}{c} -1\\ 0 \\ 0 \\ 1 \\ 1 \end{array}\right]\\$$

            <p>With custom features $x_1^2$ and $x_2^2$:</p>

            $$h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2$$

            <p>We predict $y=1$ if $-1 + x^2_1 + x^2_2 \geq 0$. The polynom can have as much custom features as you wish to fit the data. Even with non-circular non-linear decision boundaries.</p>

            <h4 id="log-reg-cost">Cost Function<a class="anchor-link" href="#log-reg-cost"></a></h4>
            <p>Notation:</p>
            <ul>
                <li>Training set: $\left\{ (x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})\right\}$</li>
                <li>$m$ examples $\;\;\;x \in \left[\begin{array}{c} x_0\\ x_1 \\ \vdots \\ x_n \end{array}\right] \; \; \; x_0 = 1, y \in \{0,1\}$</li>
                <li>$h_\theta = \frac{1}{1+e^{-\theta^Tx}}$</li>
            </ul>

            <p>The cost function for linear regression was:</p>

            $$J(\vec\theta) = \frac{1}{m} \sum^m_{i=1} \frac{1}{2}\left(h_\theta(x^{(i)}) - y^{(i)}\right)^2 = cost(h_\theta(x^{(i)}), y^{(i)})\\
            cost(h_\theta(\vec x), \vec y) = \frac{1}{2}(h_\theta(\vec x) - \vec y)^2$$

            <p>This cost function is <em>non-convex</em>. For logistic regression we want a <em>convex</em> function.</p>

            $$cost(h_\theta(\vec x), \vec y) = \left\{ \begin{array}{r} -log(h_\theta(\vec x)) \;\;\; \text{if} \;\; y = 1 \\
            -log(1 - h_\theta(\vec x)) \;\;\; \text{if} \;\; y = 0\end{array}\right.$$

            <p>If the $\text{cost} \, = 0 \; \text{if} \; y = 1, h_\theta(x) = 1$ but as $h_\theta(x) \rightarrow 0$ $Cost \rightarrow \infty$. This captures the intuition that if $h_\theta(x) = 0$ (predict $P(y=1|x;\theta)$), but $y=1$ we'll penalize the learning alrogithm by a very large cost.</p>

            <h4 id="simp-cost-grad-desc">Simplified Cost Function and Gradient Descent<a class="anchor-link" href="#simp-cost-grad-desc"></a></h4>
            <p>The cost function can be simplified to a one liner:</p>

            $$cost(h_\theta(x),x) = -y \; log(h_\theta(x)) - (1-y) log(1-h_\theta(x))$$

            <p>This works because if $y=1$, the first term will be multiplicated by $1$ and the second term will be multiplicated with $(1-y) = (1-1) = 0$. If $y=0$ the first term is multiplicated with 0 and the second term is multiplicated with $(1-0) = 1$.</p>

            <p>This gives us the complete cost function $J(\vec\theta)$:</p>

            $$\begin{align}
            J(\vec\theta) & = \frac{1}{m} \sum^m_{i=1} cost(h_\theta(x^{(i)}),y^{(i)})\\
                          & = - \frac{1}{m} \left[\sum^m_{i=1} y^{(i)} log(h_\theta(x^{(i)})) + (1-y^{(i)} ) log(1 - h_\theta( x^{(i)}))\right]
            \end{align}$$

            <p>To fit parameters $\vec\theta$ $\text{min}_\theta J(\vec\theta)$ is calculated. To make a new prediction given new x the output of $h_\theta$ has to be calculated ($P(y=1|x;\theta)$).</p>

            <h5 id="log-reg-grad-desc">Gradient Descent<a class="anchor-link" href="#log-reg-grad-desc"></a></h5>
            <p>$\text{min}_\theta J(\theta)$:</p>

            $$\begin{aligned}
            \text{repeat} &\{\\
            & \theta_j := \theta_j - \alpha \sum^m_{i=1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\\
            \} \phantom{15pt} &
            \end{aligned}$$

            <h4 id="log-reg-ad-opt">Advanced Optimization<a class="anchor-link" href="#log-reg-ad-opt"></a></h4>
            <p>In general we need to compute two things for our optimization:</p>

            <ul>
                <li>$J(\vec \theta)$</li>
                <li>$\frac{\delta}{\delta\theta_j}J(\vec \theta)$</li>
            </ul>

            <p>Besides gradient descent, there are several other algorithms that could be used:</p>

            <ul>
                <li>Conjugate Gradient</li>
                <li>BFGS</li>
                <li>L-BFGS</li>
            </ul>

            <div class="two-col">
                <h5>The advantages:</h5>
                <ul>
                    <li>No need to manually pick $\alpha$</li>
                    <li>Often faster than gradient descent</li>
                </ul>

                <h5>The disadvantages:</h5>
                <ul>
                    <li>More complex</li>
                </ul>
            </div>

            <h5>Example for $\text{min}_\theta$</h5>
            $$\vec\theta=\left[\begin{array}{c} \theta_1 \\ \theta_2 \end{array}\right]\\
            J(\vec\theta) = (\theta_1 -5)^2 + (\theta_2 -5)^2\\
            \frac{\delta}{\delta\theta_1}=2(\theta_1 -5)\\
            \frac{\delta}{\delta\theta_2} = 2(\theta_2 - 5)$$

<pre><code class="scilab">function[jVal, gradient] = costFunction(theta)

% code to compute J(theta)
jVal = (theta(1) - 5)^2 + (theta(2)-5)^2;

gradient = zeros(2,1);

% code to compute delta/delta theta_j J(theta)
gradient(1) = 2*(theta(1)-5);
gradient(2) = 2*theta(2)-5);

options = optimset('GradObj', 'on', 'MaxIter', '100');
initialTheta = zeros(2,1);
[optTheta, functionval, exitFlag] = fminunc(@costFunction, initialTheta, options);</code></pre>
            

            <h4 id="one-vs-all-class">Multiclass Classification: One-vs-all<a class="anchor-link" href="#one-vs-all-class"></a></h4>
            <p>Classification with more than two $y$'s works like this:</p>
            $$h_\theta^{(i)}(x) = P(y=i|x;\theta) \;\;\; (i = 1,2,3,...)$$
            <p>Each $i$ has it's own hypothesis $h_\theta^{(i)}(x)$ and predicts the probability that $y=i$ for each class $i$. On a new input $x$, to make a prediction, pick the class $i$ that maximizes $\text{max}_i h_\theta^{(i)}(x)$</p>

            <hr>

            <h2 id="appendix">Appendix<a class="anchor-link" href="#appendix"></a></h2>
            <h3 id="footnotes">Footnotes<a class="anchor-link" href="#footnotes"></a></h3>

            <ol>
                <li id="footnote1">Taken from the Machine Learning Video Lecture: »What is Machine Learning?«, Minute <code>01:49</code> at <a href="https://class.coursera.org/ml-008/lecture/2" title="Video Lecture on Coursera">Coursera</a></li>
            </ol>

            <footer class="main-foot">
                <ul>
                    <li><a href="#top">Back to top</a></li>
                    <li><a href="http://www.kopimi.com/kopimi" title="kopimi"><img src="img/kopimi.svg" class="kopimi"></a></li>
                    <li>By Christian Schulze<br><a href="http://andinfinity.de">andinfinity.de</a></li>
                </ul>
            </footer>
        </div>
    </body>
</html>
