<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="HandheldFriendly" content="True">
		<meta name="MobileOptimized" content="320">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/main.css" type="text/css" media="all">

		<!-- typeplate -->
		<link rel="stylesheet" href="css/typeplate.css" type="text/css" media="all">

		<!-- MathJax -->
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
				extensions: ["tex2jax.js"],
				jax: ["input/TeX", "output/HTML-CSS"],
				tex2jax: {
					inlineMath: [ ['$','$'], ["\\(","\\)"] ],
					displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
					processEscapes: true
				},
				"HTML-CSS": { availableFonts: ["TeX"] }
			});
		</script>
		<script type="text/javascript" src="js/MathJax/MathJax.js"></script>
	</head>

	<body id="top">
		<div id="main-wrap">
			<h1>Machine Learning @ Coursera</h1>
			<h2 class="sub-h2">A cheat sheet</h2>

			<p>This cheatsheet wants to provide an overview of the concepts and the used formulas and definitions of the <em>»Machine Learning«</em> <a href="https://class.coursera.org/ml-008" title="Coursera Online Course: Machine Learning">online course at coursera</a>.</p>

			<div id="last-change">
				<p>Last changed: <time datetime="2015-02-02">February 2nd, 2015</time></p>
			</div>

			<p><strong>Please note:</strong> I changed the notation very slighty. I'll denote vectors with a little arrow on the top. Example: $\vec\theta$</p>

			<h2 class="week-indicator" id="week-1">Week 1<a class="anchor-link" href="#week-1"></a></h2>

			<h3 id="intro">Introduction<a class="anchor-link" href="#intro"></a></h3>

			<h4 class="definition" id="def-ml">Machine Learning<a class="anchor-link" href="#def-ml"></a></h4>
			<blockquote>
				»Well-posed Learning Problem: A computer program is said to <em>learn</em>
				from experience E with respect to some task T and some performance measure E,
				if its performance on T, as measured by P, improves with experience E.«
				<br>
				— <cite>Tom Mitchell (1998)</cite>
				<sup><a href="#footnote1">[1]</a></sup>
			</blockquote>

			<h4 class="definition" id="def-sl">Supervised Learning<a class="anchor-link" href="#def-sl"></a></h4>
			TODO

			<h4 class="definition" id="def-ul">Unsupervised Learning<a class="anchor-link" href="#def-ul"></a></h4>
			TODO

			<h4 class="definition" id="def-reg-prob">Regression Problem<a class="anchor-link" href="#def-reg-prob"></a></h4>
			TODO

			<h4 class="definition" id="def-class-prob">Classification Problem<a class="anchor-link" href="#def-class-prob"></a></h4>
			TODO

			<h3 id="univariate-lin-reg">Linear Regression with One Variable<a class="anchor-link" href="#univariate-lin-reg"></a></h3>
			<h4 id="model-rep">Model Representation<a class="anchor-link" href="#model-rep"></a></h4>
			<p>
				<strong>Notations:</strong>
				<ul>
					<li>$m$: number of training examples</li>
					<li>$x$'s: <em>input</em> variable/features</li>
					<li>$y$'s: <em>output</em> variables/<em>target</em variable></li>
					<li>$(x,y)$: one training example</li>
					<li>$(x^{(i)},y^{(i)})$: $i$<sup>th</sup> training example</li>
				</ul>
			</p>

			<h5 class="definition" id="univariate-hypothesis">Univariate Hypothesis<a class="anchor-link" href="#univariate-hypothesis"></a></h5>
			<p>The hypothesis function maps <em>x's</em> to <em>y's</em> ($h: x \mapsto y$). It can be represented by:</p>

			$$h_{\theta} = \theta_{0} + \theta_{1}x$$

			<p>The shorthand for the hypothesis is $h(x)$. $\theta_{i}$'s are called the parameters of the hypothesis.
			In this case the hypothesis is called <em>»Univariate Linear Regression«</em>.</p>

			<h4 id="cost-function">Cost Function<a class="anchor-link" href="#cost-function"></a></h4>
			<h5 class="definition" id="def-secf">Squared Error Cost Function<a class="anchor-link" href="#def-secf"></a></h5>
			$$J(\theta_0, \theta_1) = \frac{1}{2m} \sum^{m}_{i=1}\left(h_{\theta}(x^{(i)}) - y^{(i)}\right)^2$$

			<h4 class="def" id="grad-dec">The Gradient Descent Algorithm<a class="anchor-link" href="#grad-dec"></a></h4>
			<p>The goal is to choose the hypothises' parameters in a manner that the the output of the cost function $J(\theta_0, \theta_1)$ is minimal.</p>

			<p><strong>Outline:</strong>
				<ul>
					<li>Start with some $\theta_0, \theta_1$</li>
					<li>Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0, \theta_1)$ until we hopefully end up at a minimum</li>
				</ul>
			</p>

			<h5 class="definition" id="def-grad-dec">Gradient Descent Algorithm<a class="anchor-link" href="#def-grad-dec"></a></h5>
			<p>Note that the values of $\theta_0$ and $\theta_1$ are updated simultaneously. $\alpha$ is called the <em>learning rate.</em></p>
			$$\begin{aligned}
			\text{repeat} & \text{ until convergence} \; \{\\
			& \theta_j := \theta_j - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1) \;\; \text{(for j=0 and j=1)}\\
			\} \phantom{15pt} &
			\end{aligned}$$

			<p>The correct implementation of the simultaneous update looks like this:</p>
			$$\begin{aligned}
			& temp0 := \theta_0 - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1)\\
			& temp1 := \theta_1 - \alpha \frac{\delta}{\delta\theta_j} J(\theta_0, \theta_1)\\
			& \theta_0 := temp0 \\
			& \theta_1 := temp1
			\end{aligned}$$ 

			<h5 id="part-der-cf">Partial derivitive of the cost function<a class="anchor-link" href="#part-der-cf"></a></h5>
			$$\begin{aligned}
			\text{repeat} & \text{ until convergence} \; \{\\
			& \theta_0 := \theta_0 - \alpha \frac1{1}{m}\sum^{m}_{i=0}\left(h_\theta(x^{(i)}) - y^{(i)}\right)\\
			& \theta_1 := \theta_1 - \alpha \frac1{1}{m}\sum^{m}_{i=0}\left(h_\theta(x^{(i)}) - y^{(i)}\right) \cdot x^{(i)}\\
			\} \phantom{15pt} &
			\end{aligned}$$


			<p><strong>Note:</strong> The cost function $J(\theta_0, \theta_1)$ is <em>convex</em> and therefore has only one optimum overall.</p>

			<h5 class="definition" id="def-batch-grad-dec">Batch Gradient Descent<a class="anchor-link" href="#def-batch-grad-dec"></a></h5>
			<p>If the gradient descent uses all $m$ training examples in each iteration it is also called <em>Batch Gradient Descent Algorithm</em>.</p>

			<h2 class="week-indicator" id="week-2">Week 2<a class="anchor-link" href="#week-2"></a></h2>
			<h3 id="multivariate-lin-reg">Linear Regression with Multiple Variables<a class="anchor-link" href="#multivariate-lin-reg"></a></h3>
			<h4 id="multiple-features">Multiple Features<a class="anchor-link" href="#multiple-features"></a></h4>
			<p>
				<strong>Notations:</strong>
				<ul>
					<li>$n$: number of features</li>
					<li>$\vec x^{(i)}$: input features of <em>i<sup>th<sup></em> training example</li>
					<li>$x^{(i)}_j$: value of feature $j$ in <em>i<sup>th<sup></em> training example</li>
				</ul>
			</p>

			<h5 class="definition" id="multivariate-hypothesis">Multivariate Hypothesis<a class="anchor-link" href="#multivariate-hypothesis"></a></h5>
			$$h_\theta = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n$$

			<p>For convenience of notation we'll define $x_0 = 1$ ($x_0^{(i)}$). Thus a feature vector looks like:</p>

			$$ \vec x = \left[\begin{array}{c} x_0\\ x_1 \\ \vdots \\ x_n \end{array}\right] \in \mathbb{R}^{n+1}$$

			<p>And the parameters can be written as:</p>

			$$ \vec \theta = \left[\begin{array}{c} \theta_0\\ \theta_1 \\ \vdots \\ \theta_n \end{array}\right] \in \mathbb{R}^{n+1}$$

			<p>The hypothesis can now be written as:</p>

			$$\begin{align}
			h_\theta & = \theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n\\
			& = \left[ \theta_0 \theta_1 \cdots \theta_n \right] \left[\begin{array}{c} \theta_0\\ \theta_1 \\ \vdots \\ \theta_n \end{array}\right] \\
			& = \boxed{\vec\theta^{T}\vec x}\\
			\end{align}$$

			<p>This hypothesis is called <em>»Multivariate Linear Regression«</em>.</p>

			<h4 id="multivar-grad-desc">Gradient Descent for Multiple Variables<a class="anchor-link" href="#multivar-grad-desc"></a></h4>
			<p>The cost function can now be written as:</p>

			$$\begin{aligned}
			J(\theta_0, \theta_1, ..., \theta_n) & = \frac{1}{2m}\sum^{m}_{i=1} \left(h_\theta(x^{(i)}) - y^{(i)}\right)^2\\
			& = \boxed{J(\vec\theta)}
			\end{aligned}$$

			<p>The gradient descent algorithm for this cost function looks like this:</p>

			$$\begin{aligned}
			\text{repeat} & \{\\
			& \theta_j := \theta_j - \alpha \frac{\delta}{\delta \theta_j} \; \; J(\theta_0, \theta_1, ... , \theta_n)\\
			\} \phantom{15pt} &
			\end{aligned}$$

			<p>Which can also be written like this:</p>
			$$\begin{aligned}
			\text{repeat} & \{\\
			& \theta_j := \theta_j - \alpha \frac{1}{m} \sum^{m}_{i=1}\left( h_\theta(\vec x^{(i)}) -y^{(i)} \right) x_j^{(i)}) \\
			\} \phantom{15pt} &
			\end{aligned}$$

			<p>Again, the parameters $\theta_j \; \forall j= 0, ..., n$ have to be updated simultaneously.</p>

			<h5 id="feature-scaling">Feature Scaling<a class="anchor-link" href="#feature-scaling"></a></h5>
			<p>Get every feature into approximately a $-1 \leq x_i \leq 1$ range to
			optimize the path finding of the gradient descent algorithm.</p>

			<h6 id="mean-norm">Mean Normalization<a class="anchor-link" href="#mean-norm"></a></h6>
			<p>Replace $x_i$ with $x_i - \mu_i$ to make features have approximately zero mean
			(does not apply to $x_0 = 1$).</p>

			$$x_1 \leftarrow \frac{x_1 - \mu_1}{s_1}$$

			<p>where $\mu_1$ is the average value of x in the training set and $s_1$ is
			the range $max - min$ (or standard deviation).</p>

			<h5 id="learning-rate">Learning Rate $\alpha$<a class="anchor-link" href="#learning-rate"></a></h5>
			<p>General rule: $J(\vec\theta)$ should decrease after every iteration.</p>

			<h6>Example Automatic Convergence Test</h6>
			<p>Declare convergence if $J(\vec\theta)$ decreases by less than $\epsilon = 10^{-3}$ in one iteration.</p>

			<p>Make sure gradient descent works correctly:</p>

			<ul>
				<li>If $\alpha$ is too small: slow convergence</li>
				<li>If $\alpha$ is too large: $J(\vec\theta)$ may not decrease on every iteration and may not converge</li>
			</ul>

			<p>For $\alpha$ try: $0.001$, $0.003$, $0.01$, $0.03$, $0.1$, $0.3$, $1$ etc.</p>

			
			<h4 id="poly-reg">Features and Polynomial Regression<a class="anchor-link" href="#poly-reg"></a></h4>
			<p>You can choose your model to fit to a polynomial if you want it to behave in a
			specific way. You not only can choose to multiply/divide two or more features to create
			a new feature, you can also fit your model to a more complex polynomial. If you want your 
			model to behave for example to increase you could choose to use $(size)^2$, fit it to a 
			cubic polynomial the same way, or use $\sqrt{size}$.</p>


			<h3 id="octave-tut">Octave Tutorial<a class="anchor-link" href="#octave-tut"></a></h3>

			<hr>

			<h2 id="appendix">Appendix<a class="anchor-link" href="#appendix"></a></h2>
			<h3 id="footnotes">Footnotes<a class="anchor-link" href="#footnotes"></a></h3>

			<ol>
				<li id="footnote1">Taken from the Machine Learning Video Lecture: »What is Machine Learning?«, Minute <code>01:49</code> at <a href="https://class.coursera.org/ml-008/lecture/2" title="Video Lecture on Coursera">Coursera</a></li>
			</ol>

			<footer class="main-foot">
				<ul>
					<li><a href="#top">Back to top</a></li>
					<li><a href="http://www.kopimi.com/kopimi" title="kopimi"><img src="img/kopimi.svg" class="kopimi"></a></li>
					<li>By Christian Schulze<br><a href="http://andinfinity.de">andinfinity.de</a></li>
				</ul>
			</footer>
		</div>
	</body>
</html>
